<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Tap‑to‑Place AR (iPhone + Android) — AR Animation Only</title>
  <script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>
  <!-- Using RobotExpressive model which has multiple animations -->
  <link rel="preload" as="fetch" href="https://modelviewer.dev/shared-assets/models/RobotExpressive.usdz" type="model/vnd.usdz+zip" crossorigin>
  <style>
    html, body { height: 100%; margin: 0; }
    body { font-family: system-ui, sans-serif; background:#0b0c10; color:#eee; }
    model-viewer { width: 100%; height: 100vh; --poster-color: #0b0c10; }
    .controls { position: absolute; left: 50%; bottom: 18px; transform: translateX(-50%); z-index: 3; display:flex; gap:8px; }
    .controls button, .controls a { padding: 10px 14px; border-radius: 999px; border: none; background: #2563eb; color: #fff; font-weight: 600; box-shadow: 0 6px 18px rgba(0,0,0,.25); text-decoration:none; }
    .controls .secondary { background: rgba(255,255,255,.06); color:#e6edf3; box-shadow:none; border:1px solid rgba(255,255,255,.06); }
    .diag { position: fixed; right: 10px; bottom: 10px; font-size: 12px; color:#cbd5e1; opacity:.95; max-width: 46vw; background: rgba(0,0,0,0.45); padding:8px 10px; border-radius:8px; }
    .notes { position: fixed; left: 10px; bottom: 10px; font-size: 12px; color:#9aa1a9; max-width: 46vw; }
  </style>
</head>
<body>
  <!--
    IMPORTANT: Replace the src + ios-src below with your own hosted .glb and .usdz files
    The sandbox 404 happened because /assets/model.glb didn't exist there. Using absolute URLs avoids that.
    
    NOTE: Removed 'autoplay' attribute - animation will only play in AR mode
  -->
  <model-viewer
    id="viewer"
    src="https://modelviewer.dev/shared-assets/models/RobotExpressive.glb"
    ios-src="https://modelviewer.dev/shared-assets/models/RobotExpressive.usdz"
    alt="Animated Robot"
    ar
    ar-modes="webxr scene-viewer quick-look"
    ar-placement="floor"
    ar-scale="fixed"
    camera-controls
    tone-mapping="aces"
    shadow-intensity="1"
    interaction-prompt="auto"
  >
    <!-- model-viewer uses an <a rel="ar"> anchor in the slot="ar" for iOS Quick Look -->
    <a id="platformArLink" slot="ar" rel="ar" style="display:none"></a>

    <!-- Keep the built-in AR button inside model-viewer as a visual affordance -->
    <button slot="ar-button" id="arButton">View in your space</button>
  </model-viewer>

  <div class="controls" role="region" aria-label="AR controls">
    <button id="btnAR" type="button">View in your space</button>
    <button id="btnDiag" class="secondary" type="button">Run diagnostics</button>
    <a id="manualScene" class="secondary" href="#">Open Scene Viewer</a>
  </div>

  <div class="diag" id="diag">Initializing…</div>
  <div class="notes">Notes: Animation will automatically play when entering AR mode. Replace the <code>src</code>/<code>ios-src</code> with your own HTTPS-hosted files for production.</div>

  <script>
  (async function init() {
    const mv = document.getElementById('viewer');
    const btnAR = document.getElementById('btnAR');
    const btnDiag = document.getElementById('btnDiag');
    const manualScene = document.getElementById('manualScene');
    const platformArLink = document.getElementById('platformArLink');
    const diag = document.getElementById('diag');

    const isAndroid = () => /Android/i.test(navigator.userAgent);
    const isChrome = () => /Chrome\//i.test(navigator.userAgent) && !/CriOS/.test(navigator.userAgent);
    const isIOS = () => /iPhone|iPad|iPod/i.test(navigator.userAgent);

    function log(...parts) {
      const text = parts.map(p => (typeof p === 'object' ? JSON.stringify(p) : String(p))).join(' ');
      console.log('[AR Debug]', text);
      diag.textContent = text;
    }

    // Wait until model-viewer is registered
    try {
      await customElements.whenDefined('model-viewer');
      log('model-viewer defined');
    } catch (e) {
      log('Error waiting for model-viewer definition:', e?.message || e);
    }

    const glb = mv.getAttribute('src');
    const usdz = mv.getAttribute('ios-src');

    // Set the Quick Look anchor href (model-viewer copies from ios-src normally, but we keep it explicit)
    if (platformArLink && usdz) {
      try {
        platformArLink.href = new URL(usdz, location.href).href + '#allowsContentScaling=0';
      } catch (e) { /* ignore */ }
    }

    // Utility: probe asset with HEAD (may be blocked by CORS on some servers)
    async function probeAsset(url) {
      try {
        const res = await fetch(url, { method: 'HEAD', cache: 'no-store' });
        return { ok: res.ok, status: res.status, type: res.headers.get('content-type') };
      } catch (err) {
        return { ok: false, error: err.message || String(err) };
      }
    }

    // build Scene Viewer URL
    function sceneViewerUrlFor(glbUrl, title) {
      const file = encodeURIComponent(new URL(glbUrl, location.href).href);
      const t = encodeURIComponent(title || '3D Model');
      return `https://arvr.google.com/scene-viewer/1.0?file=${file}&mode=ar_preferred&title=${t}`;
    }

    // intent fallback for older Chrome
    function sceneViewerIntent(glbUrl, title) {
      const file = encodeURIComponent(new URL(glbUrl, location.href).href);
      const t = encodeURIComponent(title || '3D Model');
      const fallback = encodeURIComponent(location.href);
      return `intent://arvr.google.com/scene-viewer/1.0?file=${file}&mode=ar_preferred&title=${t}#Intent;scheme=https;package=com.google.ar.core;action=android.intent.action.VIEW;S.browser_fallback_url=${fallback};end;`;
    }

    // Animation control functions
    function startAnimation() {
      try {
        // Wait a moment for model to be fully loaded
        setTimeout(() => {
          if (mv.availableAnimations && mv.availableAnimations.length > 0) {
            // Use a default animation or the first available one
            const animToPlay = mv.availableAnimations.includes('Dance') ? 'Dance' : 
                              mv.availableAnimations.includes('Wave') ? 'Wave' :
                              mv.availableAnimations[0];
            
            mv.animationName = animToPlay;
            mv.play();
            log('Animation started in AR mode: ' + animToPlay);
            log('All available animations: ' + JSON.stringify(mv.availableAnimations));
          } else {
            log('No animations available to play. Available:', mv.availableAnimations);
            // Force check again after a delay
            setTimeout(() => {
              if (mv.availableAnimations && mv.availableAnimations.length > 0) {
                mv.animationName = mv.availableAnimations[0];
                mv.play();
                log('Delayed animation start: ' + mv.animationName);
              }
            }, 500);
          }
        }, 200);
      } catch (e) {
        log('Error starting animation:', e?.message || e);
      }
    }

    function stopAnimation() {
      try {
        mv.pause();
        mv.currentTime = 0; // Reset to beginning
        log('Animation stopped - exited AR mode');
      } catch (e) {
        log('Error stopping animation:', e?.message || e);
      }
    }

    // Diagnostics runner
    async function runDiagnostics() {
      log('UserAgent: ' + navigator.userAgent);
      if (glb) {
        log('Probing GLB:', glb);
        const g = await probeAsset(glb);
        log('GLB probe: ' + JSON.stringify(g));
      }
      if (usdz) {
        log('Probing USDZ:', usdz);
        const u = await probeAsset(usdz);
        log('USDZ probe: ' + JSON.stringify(u));
      }

      // Check model-viewer AR readiness
      try {
        if (typeof mv.canActivateAR !== 'undefined') log('mv.canActivateAR: ' + mv.canActivateAR);
      } catch (e) { /* ignore */ }

      // Check available animations
      try {
        if (mv.availableAnimations) {
          log('Available animations: ' + JSON.stringify(mv.availableAnimations));
        }
      } catch (e) { /* ignore */ }

      // WebXR quick check
      if (navigator.xr && navigator.xr.isSessionSupported) {
        try {
          const supported = await navigator.xr.isSessionSupported('immersive-ar');
          log('navigator.xr immersive-ar supported: ' + supported);
        } catch (err) { log('navigator.xr check error: ' + (err?.message || err)); }
      } else {
        log('navigator.xr not available');
      }

      log('Diagnostics complete. Using RobotExpressive model with animations. Try AR mode!');
    }

    // wire diagnostic button
    btnDiag.addEventListener('click', async () => {
      await runDiagnostics();
    });

    // Prepare manual Scene Viewer link
    manualScene.href = glb ? sceneViewerUrlFor(glb, mv.getAttribute('alt')) : '#';
    manualScene.addEventListener('click', (e) => {
      // allow normal navigation; this link is useful when the automatic path fails
      log('Manual Scene Viewer link clicked');
    });

    // Primary AR launch
    btnAR.addEventListener('click', async (ev) => {
      ev.preventDefault();
      log('AR button clicked — checking capabilities...');

      try {
        // If model-viewer can activate AR, let it (it will choose Quick Look / Scene Viewer / WebXR)
        if (mv.canActivateAR) {
          log('Calling model-viewer.activateAR()');
          await mv.activateAR();
          return;
        }

        // If on iOS, use the Quick Look anchor (some in-app browsers still block this)
        if (isIOS()) {
          if (platformArLink && platformArLink.href) {
            log('Opening iOS Quick Look via anchor');
            platformArLink.click();
            return;
          }
        }

        // WebXR support check
        if (navigator.xr && navigator.xr.isSessionSupported) {
          try {
            const supported = await navigator.xr.isSessionSupported('immersive-ar');
            log('navigator.xr immersive-ar supported:', supported);
            if (supported) {
              // model-viewer handles this, but call activateAR just in case
              await mv.activateAR();
              return;
            }
          } catch (e) {
            log('XR isSessionSupported() error:', e?.message || e);
          }
        }

        // Android fallback: open Scene Viewer URL (https)
        if (isAndroid() && glb) {
          const url = sceneViewerUrlFor(glb, mv.getAttribute('alt'));
          log('Opening Scene Viewer (https) fallback: ' + url);
          // Open in _self to keep gesture context
          window.open(url, '_self');
          return;
        }

        log('AR not available on this device/browser. Run diagnostics or use a supported browser (Safari on iOS, Chrome on Android with ARCore).');
      } catch (err) {
        log('AR launch error: ' + (err?.message || err));
        // final fallback: Android intent
        if (isAndroid() && glb) {
          const intent = sceneViewerIntent(glb, mv.getAttribute('alt'));
          log('Falling back to intent URL: ' + intent);
          window.location.href = intent;
        }
      }
    });

    // model-viewer events - this is where we control animation based on AR status
    mv.addEventListener('ar-status', (e) => {
      const { status, reason } = e.detail || {};
      log('ar-status: ' + status + (reason ? (' | reason: ' + reason) : ''));
      
      // Start animation when AR session begins
      if (status === 'session-started') {
        // Small delay to ensure AR session is fully initialized
        setTimeout(() => {
          startAnimation();
        }, 100);
        if (navigator.vibrate) navigator.vibrate(10);
      }
      
      // Stop animation when AR session ends
      if (status === 'not-presenting' || status === 'failed') {
        stopAnimation();
      }
    });

    // Additional event listeners to ensure animation control
    mv.addEventListener('load', () => {
      log('Model loaded. Available animations:', mv.availableAnimations);
      // Wait a bit for animations to be fully parsed
      setTimeout(() => {
        log('Delayed check - Available animations:', mv.availableAnimations);
      }, 1000);
    });

    // Listen for when animations are ready
    mv.addEventListener('progress', (e) => {
      if (e.detail.totalProgress === 1) {
        log('Model fully loaded. Animations:', mv.availableAnimations);
      }
    });

    // Listen for when the model is ready in AR mode
    mv.addEventListener('ar-tracking', (e) => {
      log('AR tracking event:', e.detail);
      // Ensure animation is playing when tracking starts
      if (mv.availableAnimations && mv.availableAnimations.length > 0) {
        startAnimation();
      }
    });

    // Backup method: listen for camera-change events in AR
    mv.addEventListener('camera-change', (e) => {
      // Only in AR mode, ensure animation is playing
      if (mv.getAttribute('ar') && mv.availableAnimations && mv.availableAnimations.length > 0) {
        // Check if we're likely in AR mode by looking at camera properties
        const source = e.detail?.source;
        if (source === 'user-interaction' || source === 'automatic') {
          // Small chance we're in AR, try to start animation if not already playing
          if (!mv.paused) return; // Already playing
          setTimeout(() => {
            startAnimation();
          }, 50);
        }
      }
    });

    // Auto-run a quick diagnostics so user sees immediate feedback
    await runDiagnostics();
  })();
</script>
</body>
</html>
