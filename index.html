<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Robot AR + Sound</title>
<script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>
<style>
  html, body { height:100%; margin:0; background:#0b0c10; color:#fff; font-family:system-ui,sans-serif;}
  model-viewer { width:100%; height:100vh; display:block; }
  button[slot="ar-button"]{ 
    position: absolute; bottom: 20px; left: 50%; transform: translateX(-50%);
    padding: 12px 24px; font-size: 16px; border-radius: 8px;
    background: #ff6; color: #000; border: none; cursor: pointer;
  }
</style>
</head>
<body>

<model-viewer id="mv"
  src="https://modelviewer.dev/shared-assets/models/RobotExpressive.glb"
  ios-src="https://raw.githubusercontent.com/zonbita/AR-JS/main/dance.usdz"
  alt="Robot Expressive"
  ar
  ar-modes="quick-look scene-viewer webxr"
  ar-scale="auto"
  camera-controls
  shadow-intensity="1"
>
  <a slot="ar" rel="ar" href="https://raw.githubusercontent.com/zonbita/AR-JS/main/dance.usdz"></a>
</model-viewer>

<audio id="robot-sound" src="https://raw.githubusercontent.com/zonbita/AR-JS/main/lactroi.mp3" loop></audio>

<script>
const mv = document.getElementById('mv');
const audio = document.getElementById('robot-sound');

const isIOS = () => /(iPhone|iPad|iPod)/i.test(navigator.userAgent) && !window.MSStream;

// --------------------
// WebXR: play animation + audio when AR session starts
mv.addEventListener("ar-status", e => {
  if (e.detail.status === "session-started") {
    if (navigator.vibrate) navigator.vibrate(20);

    // Start animation
    const anims = mv.availableAnimations || [];
    if (anims.length > 0) {
      const chosen = anims.includes("Dance") ? "Dance" : anims[0];
      mv.animationName = chosen;
      mv.timeScale = 1;
      mv.loop = true;
      if (mv.play) mv.play();
    }

    // Start audio
    audio.currentTime = 0;
    audio.play().catch(()=>console.log("[WebXR] Audio blocked"));
  } else if (e.detail.status==="not-presenting" || e.detail.status==="failed") {
    audio.pause();
    audio.currentTime = 0;
    try { mv.pause(); mv.currentTime=0; } catch(e) {}
  }
});

// --------------------
// iOS Quick Look: play audio on AR button tap
if(isIOS()){
  function attachIOSAudio(){
    const arButton = mv.shadowRoot.querySelector('button[slot="ar-button"]');
    if(arButton){
      arButton.addEventListener('click', ()=>{
        audio.currentTime = 0;
        audio.play().catch(()=>console.log("[iOS] Audio blocked"));
      });
    } else {
      setTimeout(attachIOSAudio, 200); // retry until button exists
    }
  }
  attachIOSAudio();
}
</script>

</body>
</html>
