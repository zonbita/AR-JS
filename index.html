<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Robot AR + Sound</title>
<script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>
<style>
  html, body { height:100%; margin:0; background:#0b0c10; color:#fff; font-family:system-ui,sans-serif;}
  model-viewer { width:100%; height:100vh; display:block; }
  #overlay {
    position:fixed; inset:0; display:flex; justify-content:center; align-items:center;
    background: rgba(0,0,0,0.6); color:#fff; font-size:18px; cursor:pointer; z-index:10;
    flex-direction: column; text-align:center;
  }
  #overlay p { font-size:14px; color:#ccc; margin-top:6px;}
  button[slot="ar-button"]{display:none;}
</style>
</head>
<body>

<model-viewer id="mv"
  src="https://modelviewer.dev/shared-assets/models/RobotExpressive.glb"
  ios-src="https://raw.githubusercontent.com/zonbita/AR-JS/main/dance.usdz"
  alt="Robot Expressive"
  ar
  ar-modes="quick-look scene-viewer webxr"
  ar-scale="auto"
  camera-controls
  shadow-intensity="1"
>
  <a slot="ar" rel="ar" href="https://raw.githubusercontent.com/zonbita/AR-JS/main/dance.usdz">
    <img src="https://modelviewer.dev/assets/ShopifyModels/RobotExpressive.webp" width="1" height="1" alt="Robot Preview">
  </a>
</model-viewer>

<audio id="robot-sound" src="https://raw.githubusercontent.com/zonbita/AR-JS/main/lactroi.mp3" loop></audio>

<div id="overlay">
  <div>Tap anywhere to enter AR</div>
  <p>iPhone: Safari only | Android: Chrome</p>
</div>

<script>
(async function(){
  const mv = document.getElementById('mv');
  const overlay = document.getElementById('overlay');
  const arLink = mv.querySelector('a[rel="ar"]');
  const audio = document.getElementById('robot-sound');

  const isIOS = () => /(iPhone|iPad|iPod)/i.test(navigator.userAgent) && !window.MSStream;
  const isAndroid = () => /Android/i.test(navigator.userAgent);

  // Trigger AR and audio only on user tap
  function triggerAR(){
    overlay.remove();

    if(isIOS() && arLink && arLink.href){
      // Play audio in user gesture before opening Quick Look
      audio.currentTime = 0;
      audio.play().catch(()=>console.log("[iOS] Audio blocked"));
      arLink.click();
      return;
    }

    if(mv.canActivateAR){
      // WebXR on Android
      mv.activateAR().catch(()=>console.log("[WebXR] activateAR failed"));
      return;
    }

    if(isAndroid() && mv.src){
      window.location.href = mv.src;
    }
  }

  overlay.addEventListener("click", triggerAR, {once:true});
  document.addEventListener("touchstart", triggerAR, {once:true});

  // WebXR: play animation and audio when AR session starts
  mv.addEventListener("ar-status", e=>{
    if(e.detail.status === "session-started"){
      if(navigator.vibrate) navigator.vibrate(20);

      // Play animation
      const anims = mv.availableAnimations || [];
      if(anims.length > 0){
        const chosen = anims.includes("Dance") ? "Dance" : anims[0];
        mv.animationName = chosen;
        mv.timeScale = 1;
        mv.loop = true;
        if(mv.play) mv.play();
      }

      // Play audio
      audio.currentTime = 0;
      audio.play().catch(()=>console.log("[WebXR] Audio blocked"));
    } else if(e.detail.status==="not-presenting" || e.detail.status==="failed"){
      audio.pause();
      audio.currentTime = 0;
      try{ mv.pause(); mv.currentTime=0;} catch(e){}
    }
  });
})();
</script>

</body>
</html>
